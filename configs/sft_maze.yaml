model:
  name_or_path: Qwen/Qwen2-0.5B-Instruct
  torch_dtype: auto
  device_map: auto

environment:
  name: maze
  min_dist: 2
  max_dist: 5
  seed: 42
  size: 50

sft:
  output_file: /home/rlvr_experiments/data_gen/data/maze_sft_sample.jsonl
  max_samples: 200
  think_start_token: "<think>"
  think_end_token: "</think>"
  answer_start_token: "<answer>"
  answer_end_token: "</answer>"
  ignore_index: -100 # Standard ignore index for loss
  system_prompt: "You are a helpful assistant. You are given a problem and its correct solution. Your task is to generate the step-by-step reasoning that leads to this solution. Output the reasoning inside <think></think> tags and the final answer inside <answer></answer> tags."

training:
  output_dir: outputs/maze-sft
  learning_rate: 2.0e-5
  num_train_epochs: 2
  batch_size: 2
  gradient_accumulation_steps: 4
  logging_steps: 1
  save_strategy: epoch
  bf16: true
  max_seq_length: 1024
  report_to:
    - tensorboard
